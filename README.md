# Transformer

Implementation of the famous 2017 paper "Attention is all you need"
